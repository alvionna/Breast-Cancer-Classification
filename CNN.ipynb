{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from math import floor, ceil\n",
    "from pylab import rcParams\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, auc\n",
    "%matplotlib inline\n",
    "import os\n",
    "import random as rn\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "PYTHONHASHSEED=0\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "rn.seed(1254)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitBIRADSScore(score):\n",
    "    for i in range(score.size):\n",
    "        if score[i]>0 and score[i]<4:\n",
    "            score[i]=1\n",
    "        if score[i]==4:\n",
    "            score[i]=2\n",
    "        if score[i]>4:\n",
    "            score[i]=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeRADSZero(inData):\n",
    "    BiClassData = np.copy(inData)\n",
    "    for i in range(BiClassData.shape[0]):\n",
    "        if(i<BiClassData.shape[0]):\n",
    "            if(BiClassData[i, 1]==0):\n",
    "                # print('hi')\n",
    "                BiClassData=np.delete(BiClassData, i, 0)\n",
    "    return BiClassData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "trainData = pd.read_csv('CroppedPicsTrain.csv', sep=',', header = None).values\n",
    "#malignant or benign as y\n",
    "yMoBTrain=trainData[:,0]\n",
    "#level of classification as y\n",
    "yRADSTrain=trainData[:,1]\n",
    "XTrain = trainData[:, 2:trainData.shape[1]]\n",
    "#split the BI-RADS y data (yROITrain) into four categories (we may want to consider excluding zero samples if we are getting low validity rates)\n",
    "#0: inconclusive mammogram (difficult to read or interpret) (so might want to exclude these samples)\n",
    "#1: probably benign (BI-RADS score of 1-3)\n",
    "#3: suspicious abnormality (should be investigated further but may not be cancer) (BI-RADS Score of 4)\n",
    "#4: highly suspicious findings (likely to be malignant) (BI-RADS Score of 5-6)\n",
    "#note: technically 6 is only obtainable with a biopsy but beause these patients were followed up on to determine if it was malignant some have a score of 6\n",
    "#read about BI-RADS scores here: https://www.cancer.org/cancer/breast-cancer/screening-tests-and-early-detection/mammograms/understanding-your-mammogram-report.html\n",
    "splitBIRADSScore(yRADSTrain)\n",
    "\n",
    "#exclude all the data with a BIRAD score of 0\n",
    "biClassTrain = removeRADSZero(trainData)\n",
    "XBiClassTrain = biClassTrain[:, 2:biClassTrain.shape[1]]\n",
    "yBiClassTrain = biClassTrain[:, 0]\n",
    "\n",
    "testData = pd.read_csv('CroppedPicsTest.csv', sep=',', header = None).values\n",
    "#malignant or benign as y\n",
    "yMoBTest=testData[:,0]\n",
    "#level of classification as y\n",
    "yRADSTest=testData[:,1]\n",
    "splitBIRADSScore(yRADSTest)\n",
    "XTest = testData[:, 2:testData.shape[1]]\n",
    "\n",
    "biClassTest = removeRADSZero(testData)\n",
    "XBiClassTest = biClassTest[:, 2:biClassTest.shape[1]]\n",
    "yBiClassTest = biClassTest[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain = XTrain.astype('float')/255\n",
    "XTest = XTest.astype('float')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(486, 275942)\n",
      "(486, 379, 366)\n"
     ]
    }
   ],
   "source": [
    "print(XTrain.shape)\n",
    "XCCTrain = np.array([np.reshape(XTrain[1][0:138714], (379, 366))]*XTrain.shape[0])\n",
    "for i in range(1,XTrain.shape[0]):\n",
    "    XCCTrain[i]=(np.reshape(XTrain[i][0:138714], (379, 366)))\n",
    "print(XCCTrain.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(486, 138714)\n",
      "(486, 379, 366, 1)\n"
     ]
    }
   ],
   "source": [
    "XCCTrain = XTrain[:,0:138714]\n",
    "print(XCCTrain.shape)\n",
    "XCCTrain = XCCTrain.reshape(XTrain.shape[0], 379, 366, 1)\n",
    "print(XCCTrain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the CNN using the CC View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 378, 365, 64)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 189, 182, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 188, 181, 128)     32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 94, 90, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 93, 89, 128)       65664     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1059456)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                67805248  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 67,904,193\n",
      "Trainable params: 67,904,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 486 samples\n",
      "Epoch 1/100\n",
      "486/486 [==============================] - 84s 172ms/sample - loss: 103703.4963 - accuracy: 0.4650\n",
      "Epoch 2/100\n",
      "486/486 [==============================] - 85s 174ms/sample - loss: 103276.2003 - accuracy: 0.5206\n",
      "Epoch 3/100\n",
      "486/486 [==============================] - 86s 177ms/sample - loss: 102860.6207 - accuracy: 0.4897\n",
      "Epoch 4/100\n",
      "486/486 [==============================] - 87s 180ms/sample - loss: 102455.7569 - accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "486/486 [==============================] - 91s 188ms/sample - loss: 102060.8742 - accuracy: 0.5453\n",
      "Epoch 6/100\n",
      "486/486 [==============================] - 96s 198ms/sample - loss: 101675.0854 - accuracy: 0.4897\n",
      "Epoch 7/100\n",
      "486/486 [==============================] - 93s 191ms/sample - loss: 101297.7666 - accuracy: 0.5021\n",
      "Epoch 8/100\n",
      "486/486 [==============================] - 95s 196ms/sample - loss: 100928.5101 - accuracy: 0.5267\n",
      "Epoch 9/100\n",
      "486/486 [==============================] - 93s 192ms/sample - loss: 100566.7735 - accuracy: 0.5185\n",
      "Epoch 10/100\n",
      "486/486 [==============================] - 92s 189ms/sample - loss: 100212.1224 - accuracy: 0.5103\n",
      "Epoch 11/100\n",
      "486/486 [==============================] - 95s 196ms/sample - loss: 99864.2862 - accuracy: 0.5432\n",
      "Epoch 12/100\n",
      "486/486 [==============================] - 94s 194ms/sample - loss: 99522.9461 - accuracy: 0.5247\n",
      "Epoch 13/100\n",
      "486/486 [==============================] - 93s 192ms/sample - loss: 99187.4661 - accuracy: 0.5062\n",
      "Epoch 14/100\n",
      "486/486 [==============================] - 93s 192ms/sample - loss: 98857.8771 - accuracy: 0.5494\n",
      "Epoch 15/100\n",
      "486/486 [==============================] - 92s 188ms/sample - loss: 98533.7768 - accuracy: 0.5391\n",
      "Epoch 16/100\n",
      "486/486 [==============================] - 93s 191ms/sample - loss: 98214.7933 - accuracy: 0.5700\n",
      "Epoch 17/100\n",
      "486/486 [==============================] - 92s 188ms/sample - loss: 97900.6361 - accuracy: 0.5082\n",
      "Epoch 18/100\n",
      "486/486 [==============================] - 92s 189ms/sample - loss: 97590.8050 - accuracy: 0.5473\n",
      "Epoch 19/100\n",
      "486/486 [==============================] - 92s 189ms/sample - loss: 97284.8383 - accuracy: 0.5412\n",
      "Epoch 20/100\n",
      "486/486 [==============================] - 93s 192ms/sample - loss: 96982.1698 - accuracy: 0.5700\n",
      "Epoch 21/100\n",
      "486/486 [==============================] - 92s 189ms/sample - loss: 96682.4081 - accuracy: 0.5720\n",
      "Epoch 22/100\n",
      "486/486 [==============================] - 91s 188ms/sample - loss: 96384.8193 - accuracy: 0.5864\n",
      "Epoch 23/100\n",
      "486/486 [==============================] - 96s 198ms/sample - loss: 96088.9697 - accuracy: 0.5864\n",
      "Epoch 24/100\n",
      "486/486 [==============================] - 91s 186ms/sample - loss: 95794.1966 - accuracy: 0.5926\n",
      "Epoch 25/100\n",
      "486/486 [==============================] - 90s 185ms/sample - loss: 95500.1160 - accuracy: 0.5617\n",
      "Epoch 26/100\n",
      "486/486 [==============================] - 88s 181ms/sample - loss: 95205.8758 - accuracy: 0.5679\n",
      "Epoch 27/100\n",
      "486/486 [==============================] - 86s 176ms/sample - loss: 94911.2930 - accuracy: 0.6173\n",
      "Epoch 28/100\n",
      "486/486 [==============================] - 83s 172ms/sample - loss: 94616.1618 - accuracy: 0.5967\n",
      "Epoch 29/100\n",
      "486/486 [==============================] - 86s 177ms/sample - loss: 94320.1139 - accuracy: 0.6029\n",
      "Epoch 30/100\n",
      "486/486 [==============================] - 84s 174ms/sample - loss: 94023.2964 - accuracy: 0.5720\n",
      "Epoch 31/100\n",
      "486/486 [==============================] - 84s 173ms/sample - loss: 93725.7230 - accuracy: 0.6193\n",
      "Epoch 32/100\n",
      "486/486 [==============================] - 85s 175ms/sample - loss: 93427.8703 - accuracy: 0.6296\n",
      "Epoch 33/100\n",
      "486/486 [==============================] - 85s 174ms/sample - loss: 93130.3014 - accuracy: 0.6091\n",
      "Epoch 34/100\n",
      "486/486 [==============================] - 84s 173ms/sample - loss: 92833.6168 - accuracy: 0.6070\n",
      "Epoch 35/100\n",
      "486/486 [==============================] - 86s 176ms/sample - loss: 92539.1361 - accuracy: 0.6255\n",
      "Epoch 36/100\n",
      "486/486 [==============================] - 81s 167ms/sample - loss: 92247.6033 - accuracy: 0.6379\n",
      "Epoch 37/100\n",
      "486/486 [==============================] - 82s 169ms/sample - loss: 91960.2511 - accuracy: 0.6255\n",
      "Epoch 38/100\n",
      "486/486 [==============================] - 85s 174ms/sample - loss: 91678.1813 - accuracy: 0.6481\n",
      "Epoch 39/100\n",
      "486/486 [==============================] - 92s 189ms/sample - loss: 91402.5211 - accuracy: 0.6502\n",
      "Epoch 40/100\n",
      "486/486 [==============================] - 86s 176ms/sample - loss: 91134.0129 - accuracy: 0.6564\n",
      "Epoch 41/100\n",
      "486/486 [==============================] - 84s 173ms/sample - loss: 90873.4722 - accuracy: 0.6667\n",
      "Epoch 42/100\n",
      "486/486 [==============================] - 88s 182ms/sample - loss: 90621.0638 - accuracy: 0.6852\n",
      "Epoch 43/100\n",
      "486/486 [==============================] - 87s 178ms/sample - loss: 90377.4090 - accuracy: 0.6687\n",
      "Epoch 44/100\n",
      "486/486 [==============================] - 87s 179ms/sample - loss: 90141.9254 - accuracy: 0.7263\n",
      "Epoch 45/100\n",
      "486/486 [==============================] - 87s 178ms/sample - loss: 89915.1982 - accuracy: 0.7243\n",
      "Epoch 46/100\n",
      "486/486 [==============================] - 86s 177ms/sample - loss: 89696.3317 - accuracy: 0.6749\n",
      "Epoch 47/100\n",
      "486/486 [==============================] - 86s 178ms/sample - loss: 89485.0119 - accuracy: 0.7407\n",
      "Epoch 48/100\n",
      "486/486 [==============================] - 85s 175ms/sample - loss: 89280.6172 - accuracy: 0.7819\n",
      "Epoch 49/100\n",
      "486/486 [==============================] - 89s 183ms/sample - loss: 89082.7179 - accuracy: 0.7695\n",
      "Epoch 50/100\n",
      "486/486 [==============================] - 89s 183ms/sample - loss: 88890.3926 - accuracy: 0.7819\n",
      "Epoch 51/100\n",
      "486/486 [==============================] - 88s 181ms/sample - loss: 88703.1706 - accuracy: 0.7469\n",
      "Epoch 52/100\n",
      "486/486 [==============================] - 86s 178ms/sample - loss: 88520.3990 - accuracy: 0.8272\n",
      "Epoch 53/100\n",
      "486/486 [==============================] - 86s 177ms/sample - loss: 88341.3615 - accuracy: 0.8045\n",
      "Epoch 54/100\n",
      "486/486 [==============================] - 85s 174ms/sample - loss: 88165.4625 - accuracy: 0.7325\n",
      "Epoch 55/100\n",
      "486/486 [==============================] - 88s 181ms/sample - loss: 87991.9899 - accuracy: 0.7757\n",
      "Epoch 56/100\n",
      "486/486 [==============================] - 87s 178ms/sample - loss: 87820.4216 - accuracy: 0.7819\n",
      "Epoch 57/100\n",
      "486/486 [==============================] - 86s 177ms/sample - loss: 87649.8265 - accuracy: 0.7757\n",
      "Epoch 58/100\n",
      "486/486 [==============================] - 89s 183ms/sample - loss: 87479.9159 - accuracy: 0.7942\n",
      "Epoch 59/100\n",
      "486/486 [==============================] - 91s 188ms/sample - loss: 87309.7536 - accuracy: 0.8292\n",
      "Epoch 60/100\n",
      "486/486 [==============================] - 89s 182ms/sample - loss: 87138.6814 - accuracy: 0.8128\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486/486 [==============================] - 86s 178ms/sample - loss: 86966.1880 - accuracy: 0.8354\n",
      "Epoch 62/100\n",
      "486/486 [==============================] - 88s 181ms/sample - loss: 86791.5347 - accuracy: 0.8519\n",
      "Epoch 63/100\n",
      "486/486 [==============================] - 90s 186ms/sample - loss: 86613.8889 - accuracy: 0.8230\n",
      "Epoch 64/100\n",
      "486/486 [==============================] - 93s 191ms/sample - loss: 86432.9173 - accuracy: 0.8498\n",
      "Epoch 65/100\n",
      "486/486 [==============================] - 92s 188ms/sample - loss: 86247.7974 - accuracy: 0.8704\n",
      "Epoch 66/100\n",
      "486/486 [==============================] - 90s 185ms/sample - loss: 86058.3551 - accuracy: 0.8992\n",
      "Epoch 67/100\n",
      "486/486 [==============================] - 91s 188ms/sample - loss: 85864.3005 - accuracy: 0.8930\n",
      "Epoch 68/100\n",
      "486/486 [==============================] - 92s 190ms/sample - loss: 85665.4818 - accuracy: 0.8354\n",
      "Epoch 69/100\n",
      "486/486 [==============================] - 90s 185ms/sample - loss: 85462.3681 - accuracy: 0.8909\n",
      "Epoch 70/100\n",
      "486/486 [==============================] - 90s 185ms/sample - loss: 85255.3138 - accuracy: 0.8971\n",
      "Epoch 71/100\n",
      "486/486 [==============================] - 91s 186ms/sample - loss: 85045.4851 - accuracy: 0.9033\n",
      "Epoch 72/100\n",
      "486/486 [==============================] - 90s 185ms/sample - loss: 84833.7986 - accuracy: 0.8704\n",
      "Epoch 73/100\n",
      "486/486 [==============================] - 90s 184ms/sample - loss: 84621.5989 - accuracy: 0.8745\n",
      "Epoch 74/100\n",
      "486/486 [==============================] - 94s 193ms/sample - loss: 84410.2357 - accuracy: 0.9136\n",
      "Epoch 75/100\n",
      "486/486 [==============================] - 92s 190ms/sample - loss: 84201.7271 - accuracy: 0.9321\n",
      "Epoch 76/100\n",
      "486/486 [==============================] - 90s 185ms/sample - loss: 83996.5178 - accuracy: 0.8807\n",
      "Epoch 77/100\n",
      "486/486 [==============================] - 90s 185ms/sample - loss: 83796.2501 - accuracy: 0.9300\n",
      "Epoch 78/100\n",
      "486/486 [==============================] - 95s 195ms/sample - loss: 83601.3828 - accuracy: 0.8889\n",
      "Epoch 79/100\n",
      "486/486 [==============================] - 89s 183ms/sample - loss: 83412.1013 - accuracy: 0.9383\n",
      "Epoch 80/100\n",
      "486/486 [==============================] - 88s 182ms/sample - loss: 83228.5383 - accuracy: 0.9115\n",
      "Epoch 81/100\n",
      "486/486 [==============================] - 89s 183ms/sample - loss: 83050.0885 - accuracy: 0.8992\n",
      "Epoch 82/100\n",
      "486/486 [==============================] - 87s 178ms/sample - loss: 82876.0309 - accuracy: 0.9424\n",
      "Epoch 83/100\n",
      "486/486 [==============================] - 84s 173ms/sample - loss: 82705.5846 - accuracy: 0.9115\n",
      "Epoch 84/100\n",
      "486/486 [==============================] - 87s 179ms/sample - loss: 82537.7470 - accuracy: 0.9156\n",
      "Epoch 85/100\n",
      "486/486 [==============================] - 86s 178ms/sample - loss: 82371.4397 - accuracy: 0.9074\n",
      "Epoch 86/100\n",
      "486/486 [==============================] - 84s 174ms/sample - loss: 82205.8316 - accuracy: 0.9342\n",
      "Epoch 87/100\n",
      "486/486 [==============================] - 87s 179ms/sample - loss: 82039.9081 - accuracy: 0.9321\n",
      "Epoch 88/100\n",
      "486/486 [==============================] - 85s 176ms/sample - loss: 81873.1568 - accuracy: 0.9588\n",
      "Epoch 89/100\n",
      "486/486 [==============================] - 84s 172ms/sample - loss: 81705.1969 - accuracy: 0.9444\n",
      "Epoch 90/100\n",
      "486/486 [==============================] - 86s 177ms/sample - loss: 81535.8065 - accuracy: 0.9465\n",
      "Epoch 91/100\n",
      "486/486 [==============================] - 85s 175ms/sample - loss: 81365.2277 - accuracy: 0.9486\n",
      "Epoch 92/100\n",
      "486/486 [==============================] - 86s 176ms/sample - loss: 81193.8720 - accuracy: 0.9568\n",
      "Epoch 93/100\n",
      "486/486 [==============================] - 86s 176ms/sample - loss: 81022.5003 - accuracy: 0.9342\n",
      "Epoch 94/100\n",
      "486/486 [==============================] - 86s 178ms/sample - loss: 80851.7970 - accuracy: 0.9362\n",
      "Epoch 95/100\n",
      "486/486 [==============================] - 86s 177ms/sample - loss: 80682.7599 - accuracy: 0.9465\n",
      "Epoch 96/100\n",
      "486/486 [==============================] - 84s 173ms/sample - loss: 80516.3749 - accuracy: 0.9712\n",
      "Epoch 97/100\n",
      "486/486 [==============================] - 86s 178ms/sample - loss: 80353.3992 - accuracy: 0.9691\n",
      "Epoch 98/100\n",
      "486/486 [==============================] - 91s 187ms/sample - loss: 80195.4759 - accuracy: 0.9712\n",
      "Epoch 99/100\n",
      "486/486 [==============================] - 89s 184ms/sample - loss: 80043.5579 - accuracy: 0.9774\n",
      "Epoch 100/100\n",
      "486/486 [==============================] - 87s 178ms/sample - loss: 79898.5240 - accuracy: 0.9753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d552d1e908>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annImageModel = tf.keras.models.Sequential()\n",
    "#first argument = number of output in the layer \n",
    "#second argument = the filter/kernel size (tuple)\n",
    "#input_shape = (batch_size, image size pixel, image size pixel, depth)\n",
    "#in this case, 32 x 32 RGB picture with depth of 3\n",
    "annImageModel.add(tf.keras.layers.Conv2D(64, (2, 2), activation='tanh', input_shape=(379, 366, 1), kernel_regularizer=tf.keras.regularizers.l2(0.01), bias_regularizer = tf.keras.regularizers.l2(0.01), activity_regularizer = tf.keras.regularizers.l2(0.01)))\n",
    "#padding = 'valid' -> adds no padding\n",
    "annImageModel.add(tf.keras.layers.MaxPooling2D((2, 2), padding = 'valid'))\n",
    "annImageModel.add(tf.keras.layers.Conv2D(128, (2, 2), activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(0.01), bias_regularizer = tf.keras.regularizers.l2(0.01), activity_regularizer = tf.keras.regularizers.l2(0.01)))\n",
    "annImageModel.add(tf.keras.layers.MaxPooling2D((2, 2), padding = 'valid'))\n",
    "annImageModel.add(tf.keras.layers.Conv2D(128, (2, 2), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01), bias_regularizer = tf.keras.regularizers.l2(0.01), activity_regularizer = tf.keras.regularizers.l2(0.01)))\n",
    "#changing the model from 3D to 1D (where the input of dense has to be 1D)\n",
    "annImageModel.add(tf.keras.layers.Flatten())\n",
    "annImageModel.add(tf.keras.layers.Dense(64, activation = 'tanh'))\n",
    "#annImageModel.add(tf.keras.layers.Dense(28, activation = 'tanh'))\n",
    "#annImageModel.add(tf.keras.layers.Dense(8, activation = 'tanh'))\n",
    "annImageModel.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "optimizer = tf.optimizers.Adam(lr = 0.000001)\n",
    "annImageModel.compile(optimizer, loss = 'binary_crossentropy', metrics =['accuracy'])\n",
    "annImageModel.summary()\n",
    "#train the model\n",
    "annImageModel.fit(XCCTrain, yMoBTrain, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 7s 49ms/sample - loss: 78978.4403 - accuracy: 0.6986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[78978.44028253424, 0.69863015]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "XCCTest = XTest[:,0:138714]\n",
    "#print(XCCTest.shape)\n",
    "XCCTest = XCCTest.reshape(XTest.shape[0], 379, 366, 1)\n",
    "#print(XCCTrain.shape)\n",
    "annImageModel.evaluate(XCCTest, yMoBTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Using the MLO View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(486, 137228)\n",
      "(486, 377, 364, 1)\n"
     ]
    }
   ],
   "source": [
    "XMLOTrain = XTrain[:,138714:]\n",
    "print(XMLOTrain.shape)\n",
    "XMLOTrain = XMLOTrain.reshape(XTrain.shape[0], 377, 364, 1)\n",
    "print(XMLOTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 376, 363, 64)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 188, 181, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 187, 180, 128)     32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 93, 90, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 92, 89, 128)       65664     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1048064)           0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                67076160  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 67,175,105\n",
      "Trainable params: 67,175,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "annImageModel = tf.keras.models.Sequential()\n",
    "#first argument = number of output in the layer \n",
    "#second argument = the filter/kernel size (tuple)\n",
    "#input_shape = (batch_size, image size pixel, image size pixel, depth)\n",
    "#in this case, 32 x 32 RGB picture with depth of 3\n",
    "annImageModel.add(tf.keras.layers.Conv2D(64, (2, 2), activation='tanh', input_shape=(377, 364, 1), kernel_regularizer=tf.keras.regularizers.l2(0.01), bias_regularizer = tf.keras.regularizers.l2(0.01), activity_regularizer = tf.keras.regularizers.l2(0.01)))\n",
    "#padding = 'valid' -> adds no padding\n",
    "annImageModel.add(tf.keras.layers.MaxPooling2D((2, 2), padding = 'valid'))\n",
    "annImageModel.add(tf.keras.layers.Conv2D(128, (2, 2), activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(0.01), bias_regularizer = tf.keras.regularizers.l2(0.01), activity_regularizer = tf.keras.regularizers.l2(0.01)))\n",
    "annImageModel.add(tf.keras.layers.MaxPooling2D((2, 2), padding = 'valid'))\n",
    "annImageModel.add(tf.keras.layers.Conv2D(128, (2, 2), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01), bias_regularizer = tf.keras.regularizers.l2(0.01), activity_regularizer = tf.keras.regularizers.l2(0.01)))\n",
    "#changing the model from 3D to 1D (where the input of dense has to be 1D)\n",
    "annImageModel.add(tf.keras.layers.Flatten())\n",
    "annImageModel.add(tf.keras.layers.Dense(64, activation = 'tanh'))\n",
    "#annImageModel.add(tf.keras.layers.Dense(28, activation = 'tanh'))\n",
    "#annImageModel.add(tf.keras.layers.Dense(8, activation = 'tanh'))\n",
    "annImageModel.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "optimizer = tf.optimizers.Adam(lr = 0.000001)\n",
    "annImageModel.compile(optimizer, loss = 'binary_crossentropy', metrics =['accuracy'])\n",
    "annImageModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 486 samples\n",
      "Epoch 1/100\n",
      "486/486 [==============================] - 84s 172ms/sample - loss: 96423.8741 - accuracy: 0.4465\n",
      "Epoch 2/100\n",
      "486/486 [==============================] - 88s 181ms/sample - loss: 95983.6695 - accuracy: 0.4897\n",
      "Epoch 3/100\n",
      "486/486 [==============================] - 85s 174ms/sample - loss: 95561.3632 - accuracy: 0.5267\n",
      "Epoch 4/100\n",
      "486/486 [==============================] - 88s 180ms/sample - loss: 95156.2622 - accuracy: 0.5103\n",
      "Epoch 5/100\n",
      "486/486 [==============================] - 87s 179ms/sample - loss: 94766.9660 - accuracy: 0.5556\n",
      "Epoch 6/100\n",
      "486/486 [==============================] - 88s 180ms/sample - loss: 94392.9989 - accuracy: 0.5309\n",
      "Epoch 7/100\n",
      "486/486 [==============================] - 86s 176ms/sample - loss: 94033.0540 - accuracy: 0.5021\n",
      "Epoch 8/100\n",
      "486/486 [==============================] - 87s 179ms/sample - loss: 93686.1370 - accuracy: 0.5082\n",
      "Epoch 9/100\n",
      "486/486 [==============================] - 88s 181ms/sample - loss: 93350.8831 - accuracy: 0.5082\n",
      "Epoch 10/100\n",
      "486/486 [==============================] - 86s 177ms/sample - loss: 93026.1331 - accuracy: 0.5267\n",
      "Epoch 11/100\n",
      "486/486 [==============================] - 85s 176ms/sample - loss: 92710.5492 - accuracy: 0.5494\n",
      "Epoch 12/100\n",
      "486/486 [==============================] - 89s 183ms/sample - loss: 92402.6937 - accuracy: 0.5638\n",
      "Epoch 13/100\n",
      "486/486 [==============================] - 88s 181ms/sample - loss: 92101.4529 - accuracy: 0.5556\n",
      "Epoch 14/100\n",
      "486/486 [==============================] - 88s 182ms/sample - loss: 91805.2924 - accuracy: 0.5658\n",
      "Epoch 15/100\n",
      "486/486 [==============================] - 86s 177ms/sample - loss: 91513.3448 - accuracy: 0.5370\n",
      "Epoch 16/100\n",
      "486/486 [==============================] - 86s 176ms/sample - loss: 91224.1739 - accuracy: 0.5926\n",
      "Epoch 17/100\n",
      "486/486 [==============================] - 88s 181ms/sample - loss: 90936.7846 - accuracy: 0.5267\n",
      "Epoch 18/100\n",
      "486/486 [==============================] - 88s 181ms/sample - loss: 90650.0799 - accuracy: 0.5700\n",
      "Epoch 19/100\n",
      "486/486 [==============================] - 84s 174ms/sample - loss: 90363.1373 - accuracy: 0.5679\n",
      "Epoch 20/100\n",
      "486/486 [==============================] - 88s 181ms/sample - loss: 90074.6936 - accuracy: 0.5802\n",
      "Epoch 21/100\n",
      "486/486 [==============================] - 85s 175ms/sample - loss: 89784.5706 - accuracy: 0.5988\n",
      "Epoch 22/100\n",
      "486/486 [==============================] - 86s 176ms/sample - loss: 89491.3561 - accuracy: 0.6255\n",
      "Epoch 23/100\n",
      "486/486 [==============================] - 84s 173ms/sample - loss: 89194.9008 - accuracy: 0.6214\n",
      "Epoch 24/100\n",
      "486/486 [==============================] - 84s 174ms/sample - loss: 88894.5656 - accuracy: 0.6276\n",
      "Epoch 25/100\n",
      "486/486 [==============================] - 86s 177ms/sample - loss: 88590.1002 - accuracy: 0.5823\n",
      "Epoch 26/100\n",
      "486/486 [==============================] - 86s 178ms/sample - loss: 88280.9286 - accuracy: 0.5864\n",
      "Epoch 27/100\n",
      "486/486 [==============================] - 86s 177ms/sample - loss: 87967.3903 - accuracy: 0.6235\n",
      "Epoch 28/100\n",
      "486/486 [==============================] - 90s 185ms/sample - loss: 87649.4926 - accuracy: 0.6296\n",
      "Epoch 29/100\n",
      "486/486 [==============================] - 100s 205ms/sample - loss: 87327.2789 - accuracy: 0.6811\n",
      "Epoch 30/100\n",
      "486/486 [==============================] - 92s 189ms/sample - loss: 87001.3532 - accuracy: 0.6255\n",
      "Epoch 31/100\n",
      "486/486 [==============================] - 88s 181ms/sample - loss: 86671.6206 - accuracy: 0.6914\n",
      "Epoch 32/100\n",
      "486/486 [==============================] - 88s 182ms/sample - loss: 86338.9577 - accuracy: 0.7037\n",
      "Epoch 33/100\n",
      "486/486 [==============================] - 86s 178ms/sample - loss: 86003.7398 - accuracy: 0.6852\n",
      "Epoch 34/100\n",
      "486/486 [==============================] - 86s 176ms/sample - loss: 85666.4311 - accuracy: 0.6975\n",
      "Epoch 35/100\n",
      "486/486 [==============================] - 84s 173ms/sample - loss: 85327.8422 - accuracy: 0.6811\n",
      "Epoch 36/100\n",
      "486/486 [==============================] - 90s 185ms/sample - loss: 84988.2254 - accuracy: 0.7099\n",
      "Epoch 37/100\n",
      "486/486 [==============================] - 85s 174ms/sample - loss: 84648.2617 - accuracy: 0.7243\n",
      "Epoch 38/100\n",
      "486/486 [==============================] - 92s 189ms/sample - loss: 84308.4777 - accuracy: 0.7037\n",
      "Epoch 39/100\n",
      "486/486 [==============================] - 98s 201ms/sample - loss: 83969.5869 - accuracy: 0.7757\n",
      "Epoch 40/100\n",
      "486/486 [==============================] - 95s 195ms/sample - loss: 83631.4537 - accuracy: 0.7510\n",
      "Epoch 41/100\n",
      "486/486 [==============================] - 91s 187ms/sample - loss: 83294.7376 - accuracy: 0.7222\n",
      "Epoch 42/100\n",
      "486/486 [==============================] - 93s 191ms/sample - loss: 82959.2233 - accuracy: 0.8313\n",
      "Epoch 43/100\n",
      "486/486 [==============================] - 90s 186ms/sample - loss: 82625.6171 - accuracy: 0.7634\n",
      "Epoch 44/100\n",
      "486/486 [==============================] - 88s 182ms/sample - loss: 82293.2087 - accuracy: 0.7881\n",
      "Epoch 45/100\n",
      "486/486 [==============================] - 92s 190ms/sample - loss: 81962.8048 - accuracy: 0.8519\n",
      "Epoch 46/100\n",
      "486/486 [==============================] - 89s 183ms/sample - loss: 81634.0501 - accuracy: 0.7819\n",
      "Epoch 47/100\n",
      "486/486 [==============================] - 90s 186ms/sample - loss: 81307.1980 - accuracy: 0.8189\n",
      "Epoch 48/100\n",
      "486/486 [==============================] - 91s 186ms/sample - loss: 80981.8844 - accuracy: 0.8436\n",
      "Epoch 49/100\n",
      "486/486 [==============================] - 89s 184ms/sample - loss: 80658.6040 - accuracy: 0.8251\n",
      "Epoch 50/100\n",
      "486/486 [==============================] - 91s 186ms/sample - loss: 80336.9322 - accuracy: 0.8519\n",
      "Epoch 51/100\n",
      "486/486 [==============================] - 90s 185ms/sample - loss: 80017.3667 - accuracy: 0.8765\n",
      "Epoch 52/100\n",
      "486/486 [==============================] - 86s 176ms/sample - loss: 79699.6254 - accuracy: 0.8807\n",
      "Epoch 53/100\n",
      "486/486 [==============================] - 86s 177ms/sample - loss: 79384.1028 - accuracy: 0.8539\n",
      "Epoch 54/100\n",
      "486/486 [==============================] - 94s 194ms/sample - loss: 79070.5394 - accuracy: 0.8086\n",
      "Epoch 55/100\n",
      "486/486 [==============================] - 94s 194ms/sample - loss: 78758.9622 - accuracy: 0.9095\n",
      "Epoch 56/100\n",
      "486/486 [==============================] - 85s 175ms/sample - loss: 78449.2839 - accuracy: 0.8210\n",
      "Epoch 57/100\n",
      "486/486 [==============================] - 86s 177ms/sample - loss: 78141.6016 - accuracy: 0.8971\n",
      "Epoch 58/100\n",
      "486/486 [==============================] - 84s 172ms/sample - loss: 77835.5323 - accuracy: 0.8786\n",
      "Epoch 59/100\n",
      "486/486 [==============================] - 84s 172ms/sample - loss: 77530.6938 - accuracy: 0.9177\n",
      "Epoch 60/100\n",
      "486/486 [==============================] - 83s 171ms/sample - loss: 77226.6980 - accuracy: 0.8827\n",
      "Epoch 61/100\n",
      "486/486 [==============================] - 88s 181ms/sample - loss: 76922.6989 - accuracy: 0.9156\n",
      "Epoch 62/100\n",
      "486/486 [==============================] - 86s 176ms/sample - loss: 76617.6235 - accuracy: 0.9300\n",
      "Epoch 63/100\n",
      "486/486 [==============================] - 83s 171ms/sample - loss: 76311.0191 - accuracy: 0.9321\n",
      "Epoch 64/100\n",
      "486/486 [==============================] - 82s 168ms/sample - loss: 76001.7071 - accuracy: 0.9074\n",
      "Epoch 65/100\n",
      "486/486 [==============================] - 83s 171ms/sample - loss: 75689.2127 - accuracy: 0.9486\n",
      "Epoch 66/100\n",
      "486/486 [==============================] - 87s 179ms/sample - loss: 75372.9608 - accuracy: 0.9444\n",
      "Epoch 67/100\n",
      "486/486 [==============================] - 84s 173ms/sample - loss: 75052.9161 - accuracy: 0.9588\n",
      "Epoch 68/100\n",
      "486/486 [==============================] - 85s 175ms/sample - loss: 74730.4981 - accuracy: 0.9239\n",
      "Epoch 69/100\n",
      "486/486 [==============================] - 84s 173ms/sample - loss: 74406.1732 - accuracy: 0.9300\n",
      "Epoch 70/100\n",
      "486/486 [==============================] - 84s 173ms/sample - loss: 74082.7612 - accuracy: 0.9691\n",
      "Epoch 71/100\n",
      "486/486 [==============================] - 87s 179ms/sample - loss: 73762.8835 - accuracy: 0.9568\n",
      "Epoch 72/100\n",
      "486/486 [==============================] - 84s 173ms/sample - loss: 73449.4903 - accuracy: 0.9712\n",
      "Epoch 73/100\n",
      "486/486 [==============================] - 86s 177ms/sample - loss: 73145.8421 - accuracy: 0.9568\n",
      "Epoch 74/100\n",
      "486/486 [==============================] - 85s 174ms/sample - loss: 72855.2236 - accuracy: 0.9506\n",
      "Epoch 75/100\n",
      "486/486 [==============================] - 85s 174ms/sample - loss: 72581.1203 - accuracy: 0.9712\n",
      "Epoch 76/100\n",
      "486/486 [==============================] - 85s 175ms/sample - loss: 72324.4786 - accuracy: 0.9774\n",
      "Epoch 77/100\n",
      "486/486 [==============================] - 85s 176ms/sample - loss: 72088.4745 - accuracy: 0.9588\n",
      "Epoch 78/100\n",
      "486/486 [==============================] - 89s 183ms/sample - loss: 71872.4492 - accuracy: 0.9568\n",
      "Epoch 79/100\n",
      "486/486 [==============================] - 85s 174ms/sample - loss: 71676.7969 - accuracy: 0.9671\n",
      "Epoch 80/100\n",
      "486/486 [==============================] - 85s 175ms/sample - loss: 71500.5422 - accuracy: 0.9486\n",
      "Epoch 81/100\n",
      "486/486 [==============================] - 87s 178ms/sample - loss: 71341.9214 - accuracy: 0.9486\n",
      "Epoch 82/100\n",
      "486/486 [==============================] - 86s 177ms/sample - loss: 71199.5052 - accuracy: 0.9712\n",
      "Epoch 83/100\n",
      "486/486 [==============================] - 86s 176ms/sample - loss: 71071.7070 - accuracy: 0.9815\n",
      "Epoch 84/100\n",
      "486/486 [==============================] - 85s 175ms/sample - loss: 70955.9432 - accuracy: 0.9753\n",
      "Epoch 85/100\n",
      "486/486 [==============================] - 92s 190ms/sample - loss: 70850.7595 - accuracy: 0.9815\n",
      "Epoch 86/100\n",
      "486/486 [==============================] - 88s 180ms/sample - loss: 70754.2298 - accuracy: 0.9774\n",
      "Epoch 87/100\n",
      "486/486 [==============================] - 87s 180ms/sample - loss: 70664.6436 - accuracy: 0.9856\n",
      "Epoch 88/100\n",
      "486/486 [==============================] - 89s 182ms/sample - loss: 70580.7015 - accuracy: 0.9959\n",
      "Epoch 89/100\n",
      "486/486 [==============================] - 87s 179ms/sample - loss: 70501.1216 - accuracy: 0.9856\n",
      "Epoch 90/100\n",
      "486/486 [==============================] - 87s 179ms/sample - loss: 70424.9429 - accuracy: 0.9959\n",
      "Epoch 91/100\n",
      "486/486 [==============================] - 86s 178ms/sample - loss: 70351.2608 - accuracy: 0.9979\n",
      "Epoch 92/100\n",
      "486/486 [==============================] - 85s 176ms/sample - loss: 70279.4456 - accuracy: 0.9918\n",
      "Epoch 93/100\n",
      "486/486 [==============================] - 90s 184ms/sample - loss: 70208.8726 - accuracy: 0.9979\n",
      "Epoch 94/100\n",
      "486/486 [==============================] - 86s 176ms/sample - loss: 70139.1533 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "486/486 [==============================] - 90s 185ms/sample - loss: 70070.1150 - accuracy: 0.9897\n",
      "Epoch 96/100\n",
      "486/486 [==============================] - 85s 175ms/sample - loss: 70001.4715 - accuracy: 0.9959\n",
      "Epoch 97/100\n",
      "486/486 [==============================] - 86s 177ms/sample - loss: 69933.2619 - accuracy: 0.9979\n",
      "Epoch 98/100\n",
      "486/486 [==============================] - 86s 176ms/sample - loss: 69865.5042 - accuracy: 0.9979\n",
      "Epoch 99/100\n",
      "486/486 [==============================] - 84s 172ms/sample - loss: 69798.3525 - accuracy: 0.9979\n",
      "Epoch 100/100\n",
      "486/486 [==============================] - 88s 182ms/sample - loss: 69732.1029 - accuracy: 0.9979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a9814412c8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annImageModel.fit(XMLOTrain, yMoBTrain, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 6s 43ms/sample - loss: 69321.6714 - accuracy: 0.6370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[69321.67144691781, 0.6369863]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "XMLOTest = XTest[:,138714:]\n",
    "#print(XCCTest.shape)\n",
    "XMLOTest = XMLOTest.reshape(XTest.shape[0], 377, 364, 1)\n",
    "#print(XCCTrain.shape)\n",
    "annImageModel.evaluate(XMLOTest, yMoBTest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
